<!DOCTYPE html>
<html class="writer-html5" lang="en" >
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1.0" />
  <title>nlpboost.dataset_config &mdash; nlpboost  documentation</title>
      <link rel="stylesheet" href="../../_static/pygments.css" type="text/css" />
      <link rel="stylesheet" href="../../_static/css/theme.css" type="text/css" />
  <!--[if lt IE 9]>
    <script src="../../_static/js/html5shiv.min.js"></script>
  <![endif]-->
  
        <script data-url_root="../../" id="documentation_options" src="../../_static/documentation_options.js"></script>
        <script src="../../_static/jquery.js"></script>
        <script src="../../_static/underscore.js"></script>
        <script src="../../_static/_sphinx_javascript_frameworks_compat.js"></script>
        <script src="../../_static/doctools.js"></script>
        <script src="../../_static/sphinx_highlight.js"></script>
    <script src="../../_static/js/theme.js"></script>
    <link rel="index" title="Index" href="../../genindex.html" />
    <link rel="search" title="Search" href="../../search.html" /> 
</head>

<body class="wy-body-for-nav"> 
  <div class="wy-grid-for-nav">
    <nav data-toggle="wy-nav-shift" class="wy-nav-side">
      <div class="wy-side-scroll">
        <div class="wy-side-nav-search" >
            <a href="../../index.html" class="icon icon-home"> nlpboost
          </a>
<div role="search">
  <form id="rtd-search-form" class="wy-form" action="../../search.html" method="get">
    <input type="text" name="q" placeholder="Search docs" />
    <input type="hidden" name="check_keywords" value="yes" />
    <input type="hidden" name="area" value="default" />
  </form>
</div>
        </div><div class="wy-menu wy-menu-vertical" data-spy="affix" role="navigation" aria-label="Navigation menu">
              <p class="caption" role="heading"><span class="caption-text">Contents:</span></p>
<ul>
<li class="toctree-l1"><a class="reference internal" href="../../readme.html">NLPBOOST: A library for automatic training and comparison of Transformer models</a></li>
<li class="toctree-l1"><a class="reference internal" href="../../modules.html">nlpboost</a></li>
</ul>

        </div>
      </div>
    </nav>

    <section data-toggle="wy-nav-shift" class="wy-nav-content-wrap"><nav class="wy-nav-top" aria-label="Mobile navigation menu" >
          <i data-toggle="wy-nav-top" class="fa fa-bars"></i>
          <a href="../../index.html">nlpboost</a>
      </nav>

      <div class="wy-nav-content">
        <div class="rst-content">
          <div role="navigation" aria-label="Page navigation">
  <ul class="wy-breadcrumbs">
      <li><a href="../../index.html" class="icon icon-home"></a></li>
          <li class="breadcrumb-item"><a href="../index.html">Module code</a></li>
      <li class="breadcrumb-item active">nlpboost.dataset_config</li>
      <li class="wy-breadcrumbs-aside">
      </li>
  </ul>
  <hr/>
</div>
          <div role="main" class="document" itemscope="itemscope" itemtype="http://schema.org/Article">
           <div itemprop="articleBody">
             
  <h1>Source code for nlpboost.dataset_config</h1><div class="highlight"><pre>
<span></span><span class="kn">from</span> <span class="nn">dataclasses</span> <span class="kn">import</span> <span class="n">dataclass</span><span class="p">,</span> <span class="n">asdict</span><span class="p">,</span> <span class="n">field</span>
<span class="kn">from</span> <span class="nn">typing</span> <span class="kn">import</span> <span class="n">Dict</span><span class="p">,</span> <span class="n">List</span><span class="p">,</span> <span class="n">Any</span>


<div class="viewcode-block" id="DatasetConfig"><a class="viewcode-back" href="../../nlpboost.html#nlpboost.dataset_config.DatasetConfig">[docs]</a><span class="nd">@dataclass</span>
<span class="k">class</span> <span class="nc">DatasetConfig</span><span class="p">:</span>
    <span class="sd">&quot;&quot;&quot;</span>
<span class="sd">    Configure a dataset for use within the AutoTrainer class.</span>

<span class="sd">    This determines how to load the dataset,</span>
<span class="sd">    whether local files are needed, whether additional splits are needed (for example when the original</span>
<span class="sd">    dataset only has train-test and we want also validation), and so on.</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    dataset_name: str</span>
<span class="sd">        The name of the dataset.</span>
<span class="sd">    alias: str</span>
<span class="sd">        Alias for the dataset, for saving it.</span>
<span class="sd">    task: str</span>
<span class="sd">        The task of the dataset. Currenlty, only classification, ner and qa (question answering) are available.</span>
<span class="sd">    fixed_training_args: Dict</span>
<span class="sd">        The training arguments (to use in transformers.TrainingArguments) for every model on this dataset, in dictionary format.</span>
<span class="sd">    is_multilabel: bool</span>
<span class="sd">        Whether it is multilabel classification</span>
<span class="sd">    multilabel_label_names: List</span>
<span class="sd">        Names of the labels for multilabel training.</span>
<span class="sd">    hf_load_kwargs: Dict</span>
<span class="sd">        Arguments for loading the dataset from the huggingface datasets&#39; hub. Example: {&#39;path&#39;: &#39;wikiann&#39;, &#39;name&#39;: &#39;es&#39;}.</span>
<span class="sd">        If None, it is assumed that all necessary files exist locally and are passed in the files field.</span>
<span class="sd">    type_load: str</span>
<span class="sd">        The type of load to perform in load_dataset; for example, if your data is in csv format (d = load_dataset(&#39;csv&#39;, ...)), this should be csv.</span>
<span class="sd">    files: Dict</span>
<span class="sd">        Files to load the dataset from, in Huggingface&#39;s datasets format. Possible keys are train, validation and test.</span>
<span class="sd">    data_field: str</span>
<span class="sd">        Field to load data from in the case of jsons loading in datasets.</span>
<span class="sd">    partial_split: bool</span>
<span class="sd">        Wheter a partial split is needed, that is, if you only have train and test sets, this should be True so that a new validation set is created.</span>
<span class="sd">    split: bool</span>
<span class="sd">        This should be true when you only have one split, that is, a big train set; this creates new validation and test sets.</span>
<span class="sd">    label_col: str</span>
<span class="sd">        Name of the label column.</span>
<span class="sd">    val_size: float</span>
<span class="sd">        In case no validation split is provided, the proportion of the training data to leave for validation.</span>
<span class="sd">    test_size: float</span>
<span class="sd">        In case no test split is provided, the proportion of the total data to leave for testing.</span>
<span class="sd">    pre_func</span>
<span class="sd">        Function to perform previous transformations. For example, if your dataset lacks a field (like xquad with title field for example), you can fix it in a function provided here.</span>
<span class="sd">    squad_v2: bool</span>
<span class="sd">        Only useful for question answering. Whether it is squad v2 format or not. Default is false.</span>
<span class="sd">    text_field: str</span>
<span class="sd">        The name of the field containing the text. Useful only in case of unique-text-field datasets,like most datasets are. In case of 2-sentences datasets like xnli or paws-x this is not useful. Default is text.</span>
<span class="sd">    is_2sents: bool</span>
<span class="sd">        Whether it is a 2 sentence dataset. Useful for processing datasets like xnli or paws-x.</span>
<span class="sd">    sentence1_field: str</span>
<span class="sd">        In case this is a 2 sents dataset, the name of the first sentence field.</span>
<span class="sd">    sentence2_field: str</span>
<span class="sd">        In case this is a 2 sents dataset, the name of the second sentence field.</span>
<span class="sd">    summary_field: str = field(</span>
<span class="sd">        The name of the field with summaries (we assume the long texts are in the text_field field). Only useful for summarization tasks. Default is summary.</span>
<span class="sd">    callbacks: List</span>
<span class="sd">        Callbacks to use inside transformers.</span>
<span class="sd">    metric_optimize: str</span>
<span class="sd">        Name of the metric you want to optimize in the hyperparameter search.</span>
<span class="sd">    direction_optimize : str</span>
<span class="sd">        Direction of the optimization problem. Whether you want to maximize or minimize metric_optimize.</span>
<span class="sd">    custom_eval_func: Any</span>
<span class="sd">        In case we want a special evaluation function, we can provide it here. It must receive EvalPredictions by trainer, like any compute_metrics function in transformers.</span>
<span class="sd">    seed : int</span>
<span class="sd">        Seed for optuna sampler.</span>
<span class="sd">    max_length_summary: int</span>
<span class="sd">        Max length of the summaries, for tokenization purposes. It will be changed depending on the ModelConfig.</span>
<span class="sd">    num_proc : int</span>
<span class="sd">        Number of processes to preprocess data.</span>
<span class="sd">    loaded_dataset: Any</span>
<span class="sd">        In case you want to do weird things like concatenating datasets or things like that, you can do that here, by passing a (non-tokenized) dataset in this field.</span>
<span class="sd">    additional_metrics: List</span>
<span class="sd">        List of additional metrics loaded from datasets, to compute over the test part.</span>
<span class="sd">    retrain_at_end: bool</span>
<span class="sd">        whether to retrain with the best performing model. In most cases this should be True, except when training 1 model with 1 set of hyperparams.</span>
<span class="sd">    config_num_labels: int</span>
<span class="sd">        Number of labels to set for the config, if None it will be computed based on number of labels detected.</span>
<span class="sd">    smoke_test: bool</span>
<span class="sd">        Whether to select only top 10 rows of the dataset for smoke testing purposes.</span>
<span class="sd">    augment_data: bool</span>
<span class="sd">        Whether to augment_data or not.</span>
<span class="sd">    data_augmentation_steps: List</span>
<span class="sd">        List of data augmentation techniques to use from NLPAugPipeline.</span>
<span class="sd">    pretokenized_dataset: Any</span>
<span class="sd">        Pre-tokenized dataset, to avoid tokenizing inside AutoTrainer, which may cause memory issues with huge datasets.</span>

<span class="sd">    Examples</span>
<span class="sd">    --------</span>
<span class="sd">    One can easily create a DatasetConfig for dataset conll2002 just with the following:</span>

<span class="sd">    &gt;&gt;&gt;from nlpboost import DatasetConfig</span>

<span class="sd">    &gt;&gt;&gt;config={&#39;fixed_train_args&#39;: {}, &#39;dataset_name&#39;: &#39;conll2002&#39;, &#39;alias&#39;: &#39;conll2002&#39;, &#39;task&#39;: &#39;ner&#39;, &#39;hf_load_kwargs&#39;: {&#39;path&#39;: &#39;conll2002&#39;, &#39;name&#39;: &#39;es&#39;}, &#39;label_col&#39;:&#39;ner_tags&#39;}</span>

<span class="sd">    &gt;&gt;&gt;config = DatasetConfig(**config)</span>
<span class="sd">    &quot;&quot;&quot;</span>

    <span class="n">dataset_name</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The name of the dataset&quot;</span><span class="p">})</span>
    <span class="n">alias</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Alias for the dataset, for saving it.&quot;</span><span class="p">})</span>
    <span class="n">task</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The task of the dataset. Currenlty, only classification, ner and qa (question answering) are available.&quot;</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="n">fixed_training_args</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The training arguments (to use in transformers.TrainingArguments) for every model on this dataset, in dictionary format.&quot;</span>
        <span class="p">}</span>
    <span class="p">)</span>
    <span class="n">is_multilabel</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether it is multilabel classification&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">multilabel_label_names</span><span class="p">:</span> <span class="n">List</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Names of the labels for multilabel training.&quot;</span><span class="p">},</span>
    <span class="p">)</span>
    <span class="n">hf_load_kwargs</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="p">(</span>
                <span class="s2">&quot;arguments for loading the dataset from the huggingface datasets&#39; hub. Example: {&#39;path&#39;: &#39;wikiann&#39;, &#39;name&#39;: &#39;es&#39;}.&quot;</span>
                <span class="s2">&quot;if None, it is assumed that all necessary files exist locally and are passed in the files field.&quot;</span>
            <span class="p">)</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">type_load</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;json&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The type of load to perform in load_dataset; for example, if your data is in csv format (d = load_dataset(&#39;csv&#39;, ...)), this should be csv.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">files</span><span class="p">:</span> <span class="n">Dict</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Files to load the dataset from, in Huggingface&#39;s datasets format. Possible keys are train, validation and test&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">data_field</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;data&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Field to load data from in the case of jsons loading in datasets. &quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">partial_split</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Wheter a partial split is needed, that is, if you only have train and test sets, this should be True so that a new validation set is created.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">split</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;This should be true when you only have one split, that is, a big train set; this creates new validation and test sets.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">label_col</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;label_list&quot;</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Name of the label column.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">val_size</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;In case no validation split is provided, the proportion of the training data to leave for validation.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">test_size</span><span class="p">:</span> <span class="nb">float</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mf">0.15</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;In case no test split is provided, the proportion of the total data to leave for testing.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">pre_func</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;function to perform previous transformations. For example, if your dataset lacks a field (like xquad with title field for example), you can fix it in a function provided here.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">remove_fields_pre_func</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to remove fields after pre_func is applied.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">squad_v2</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Only useful for question answering. Whether it is squad v2 format or not. Default is false&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">text_field</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;text&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The name of the field containing the text. Useful only in case of unique-text-field datasets,like most datasets are. In case of 2-sentences datasets like xnli or paws-x this is not useful.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">is_2sents</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether it is a 2 sentence dataset. Useful for processing datasets like xnli or paws-x.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">sentence1_field</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;In case this is a 2 sents dataset, the name of the first sentence field.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">sentence2_field</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;In case this is a 2 sents dataset, the name of the second sentence field.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">summary_field</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;summary&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;The name of the field with summaries (we assume the long texts are in the text_field field). Only useful for summarization tasks.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">callbacks</span><span class="p">:</span> <span class="n">List</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Callbacks to use inside transformers.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">metric_optimize</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;eval_loss&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Name of the metric you want to optimize in the hyperparameter search.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">direction_optimize</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;minimize&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Direction of the optimization problem. Whether you want to maximize or minimize metric_optimize.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">custom_eval_func</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;In case we want a special evaluation function, we can provide it here. It must receive EvalPredictions by trainer, like any compute_metrics function in transformers.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">seed</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span><span class="n">default</span><span class="o">=</span><span class="mi">420</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Seed for optuna sampler. &quot;</span><span class="p">})</span>
    <span class="n">max_length_summary</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">120</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Max length of the summaries, for tokenization purposes. It will be changed depending on the ModelConfig.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">num_proc</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="mi">4</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Number of processes to preprocess data.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">loaded_dataset</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;In case you want to do weird things like concatenating datasets or things like that, you can do that here, by passing a (non-tokenized) dataset in this field.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">additional_metrics</span><span class="p">:</span> <span class="n">List</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;List of additional metrics loaded from datasets, to compute over the test part.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">retrain_at_end</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">True</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;whether to retrain with the best performing model. In most cases this should be True, except when you&#39;re only training 1 model with 1 set of hyperparams.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">config_num_labels</span><span class="p">:</span> <span class="nb">int</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Number of labels to set for the config, if None it will be computed based on number of labels detected.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">smoke_test</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to select only top 10 rows of the dataset for smoke testing purposes&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">augment_data</span><span class="p">:</span> <span class="nb">bool</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">False</span><span class="p">,</span> <span class="n">metadata</span><span class="o">=</span><span class="p">{</span><span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Whether to augment_data or not.&quot;</span><span class="p">}</span>
    <span class="p">)</span>
    <span class="n">data_augmentation_steps</span><span class="p">:</span> <span class="n">List</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default_factory</span><span class="o">=</span><span class="nb">list</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;List of data augmentation techniques to use from NLPAugPipeline.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">id_field_qa</span><span class="p">:</span> <span class="nb">str</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="s2">&quot;id&quot;</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Name of the field with the unique id of the examples in a question answering dataset.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>
    <span class="n">pretokenized_dataset</span><span class="p">:</span> <span class="n">Any</span> <span class="o">=</span> <span class="n">field</span><span class="p">(</span>
        <span class="n">default</span><span class="o">=</span><span class="kc">None</span><span class="p">,</span>
        <span class="n">metadata</span><span class="o">=</span><span class="p">{</span>
            <span class="s2">&quot;help&quot;</span><span class="p">:</span> <span class="s2">&quot;Pre-tokenized dataset, to avoid tokenizing inside AutoTrainer, which may cause memory issues with huge datasets.&quot;</span>
        <span class="p">},</span>
    <span class="p">)</span>

    <span class="k">def</span> <span class="fm">__str__</span><span class="p">(</span>
        <span class="bp">self</span><span class="p">,</span>
    <span class="p">):</span>
        <span class="sd">&quot;&quot;&quot;Representation of dataset config in str.&quot;&quot;&quot;</span>
        <span class="n">self_as_dict</span> <span class="o">=</span> <span class="n">asdict</span><span class="p">(</span><span class="bp">self</span><span class="p">)</span>
        <span class="n">attrs_as_str</span> <span class="o">=</span> <span class="p">[</span><span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="n">k</span><span class="si">}</span><span class="s2">=</span><span class="si">{</span><span class="n">v</span><span class="si">}</span><span class="s2">,</span><span class="se">\n</span><span class="s2">&quot;</span> <span class="k">for</span> <span class="n">k</span><span class="p">,</span> <span class="n">v</span> <span class="ow">in</span> <span class="nb">sorted</span><span class="p">(</span><span class="n">self_as_dict</span><span class="o">.</span><span class="n">items</span><span class="p">())]</span>
        <span class="k">return</span> <span class="sa">f</span><span class="s2">&quot;</span><span class="si">{</span><span class="bp">self</span><span class="o">.</span><span class="vm">__class__</span><span class="o">.</span><span class="vm">__name__</span><span class="si">}</span><span class="s2">(</span><span class="se">\n</span><span class="si">{</span><span class="s1">&#39;&#39;</span><span class="o">.</span><span class="n">join</span><span class="p">(</span><span class="n">attrs_as_str</span><span class="p">)</span><span class="si">}</span><span class="s2">)&quot;</span></div>
</pre></div>

           </div>
          </div>
          <footer>

  <hr/>

  <div role="contentinfo">
    <p>&#169; Copyright 2022, Alejandro Vaca.</p>
  </div>

  Built with <a href="https://www.sphinx-doc.org/">Sphinx</a> using a
    <a href="https://github.com/readthedocs/sphinx_rtd_theme">theme</a>
    provided by <a href="https://readthedocs.org">Read the Docs</a>.
   

</footer>
        </div>
      </div>
    </section>
  </div>
  <script>
      jQuery(function () {
          SphinxRtdTheme.Navigation.enable(true);
      });
  </script> 

</body>
</html>